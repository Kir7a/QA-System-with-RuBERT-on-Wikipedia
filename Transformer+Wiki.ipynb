{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer+Wiki.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfN0J5NlMlCL",
        "outputId": "0ca06475-817d-4895-f241-478545b71deb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11695 sha256=78f6fda871cbf19fe32e1208450af64656278176dad8fc2fbe29677bb56efd80\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/93/6d/5b2c68b8a64c7a7a04947b4ed6d89fb557dcc6bc27d1d7f3ba\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeGHoLbQfs5m",
        "outputId": "09426ff5-4e86-44cd-c3f7-71276a64fd69"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 43.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 41.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 31.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=dd28ea6ee84e8c11461a90c3f8d458c5d24190c452cb3a35fee19f6dbef491e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "#Код для аккуратного вывода длинных строк\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "eAGDnQ1URCHH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UNXDje2DyLUZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4c882f4e-6764-4371-ae43-043098c54ec5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer, DistilBertForQuestionAnswering, DistilBertTokenizerFast\n",
        "import wikipedia as wiki"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим работу Википедии"
      ],
      "metadata": {
        "id": "XShhYByxPr9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wiki.set_lang('ru')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "LLw4I3s6ywuu",
        "outputId": "2c98b9a1-a328-4abe-a1d4-51e0ae330058"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'Пушкин'\n",
        "\n",
        "results = wiki.search(question)\n",
        "print(\"Резултаты поиска по запросу:\\n\")\n",
        "print(results)\n",
        "\n",
        "page = wiki.page(results[0])\n",
        "text = page.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "hd7h59RfygTY",
        "outputId": "ecf1d0ff-2a94-4ddc-829f-c1b48672415c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Резултаты поиска по запросу:\n",
            "\n",
            "['Пушкин, Александр Сергеевич', 'Пушкин (город)', 'Последняя дуэль и смерть Александра Пушкина', 'Пушкин, Сергей Львович', 'Гончарова, Наталья Николаевна', 'Потомки Пушкина', 'Пушкиния', 'Пушкин, Александр (значения)', 'Пушкины', 'Памятник А. С. Пушкину (Пушкин)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:300])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "4QPo6QogzqaW",
        "outputId": "c787d49e-5bad-4775-91c9-30e8c6bf93f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Алекса́ндр Серге́евич Пу́шкин (26 мая [6 июня] 1799, Москва — 29 января [10 февраля] 1837, Санкт-Петербург) — русский поэт, драматург и прозаик, заложивший основы русского реалистического направления, литературный критик и теоретик литературы, историк, публицист, журналист; один из самых авторитетны\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка модели"
      ],
      "metadata": {
        "id": "VuWzUjnxzoja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключим гугл-диск с сохраненной ранее обученной моделью\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "igD7nYf7ucjn",
        "outputId": "5b8d5eac-365d-41e0-9974-f46814dfcc5e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "NBKSnnmBpEdb",
        "outputId": "f54f73ba-3575-4824-bb9e-1014acd2c2be"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Если нужно загрузить сохраненную на гугл диск модель, то можно воспользоваться следующим кодом\n",
        "# Или можно загрузить модель с https://huggingface.co/models\n",
        "PRE_TRAINED_MODEL_NAME = 'drive/MyDrive/Colab Notebooks/test-squad-trained'\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(PRE_TRAINED_MODEL_NAME, local_files_only=True)"
      ],
      "metadata": {
        "id": "K9m8AK0XMGGx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6a9a0c72-0f43-4b2e-86c6-dd0b6ebe378f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=DistilBertForQuestionAnswering.from_pretrained(PRE_TRAINED_MODEL_NAME, local_files_only=True).to(device).eval()"
      ],
      "metadata": {
        "id": "3AXjPJPCM1jH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "989a1268-d3e1-4960-ca4f-71a003c97955"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer_to_question(question, Bert_model, n_search_pages=1, n_answers_per_page=10, max_answer_length = 30):\n",
        "  # Находим все тексты по запросу из википедии\n",
        "  results = wiki.search(question)\n",
        "  texts=[]\n",
        "  questions=[question]*n_search_pages\n",
        "  print(\"По запросу найдены следующие страницы\")\n",
        "  for ind, result in enumerate(results[:n_search_pages]):\n",
        "    page = wiki.page(result)\n",
        "    print(page)\n",
        "    texts.append(page.content)\n",
        "    \n",
        "  # Токенезируем все тексты\n",
        "  tokenized_examples = tokenizer(\n",
        "        questions,\n",
        "        texts,\n",
        "        truncation=\"only_second\",\n",
        "        stride=100,\n",
        "        max_length=400,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",)\n",
        "  \n",
        "  sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "  tokenized_examples[\"text_id\"] = []\n",
        "  tokenized_examples[\"offset index\"] = []\n",
        "  for i in range(len(tokenized_examples[\"input_ids\"])):\n",
        "    sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "    context_index = 1\n",
        "\n",
        "    sample_index = sample_mapping[i]\n",
        "    tokenized_examples[\"text_id\"].append(sample_index)\n",
        "\n",
        "    # Заполняем offset_mapping. Если токен не попадает в последовательность контекста, то запоминаем None\n",
        "    tokenized_examples[\"offset_mapping\"].append([\n",
        "            (o if sequence_ids[k] == context_index else None)\n",
        "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])])\n",
        "    \n",
        "  with torch.no_grad():\n",
        "    output= Bert_model(torch.LongTensor(tokenized_examples['input_ids']).to(device),\n",
        "                       attention_mask=torch.LongTensor(tokenized_examples['attention_mask']).to(device))\n",
        "  predictions = postprocess_qa_predictions(texts, tokenized_examples, output, \n",
        "                                           n_best_size = n_answers_per_page, max_answer_length = max_answer_length)\n",
        "  return predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "V7ZqC9quR58f",
        "outputId": "c4bdd2fe-0ce1-4c0a-9198-6a955f0b6abc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n",
        "    # Генерация финального предсказания ответа. Будем перебирать n_best_size ответов и выберем тот, у которого самый большой score\n",
        "    all_start_logits, all_end_logits = raw_predictions['start_logits'].cpu().numpy(), raw_predictions['end_logits'].cpu().numpy()\n",
        "    # Соответствие между примером из датасета и последовательностью токенов.\n",
        "    features_per_example = {}\n",
        "    for i, text_ind in enumerate(features['text_id']):\n",
        "      if text_ind in features_per_example:\n",
        "        features_per_example[text_ind].append(i)\n",
        "      else:\n",
        "        features_per_example[text_ind]=[i]\n",
        "\n",
        "    valid_answers = []\n",
        "\n",
        "    for example_index, example in enumerate(examples):\n",
        "        # Индекс последовательности токенов, которая соответствует данному примеру.\n",
        "        feature_indices = features_per_example[example_index]\n",
        "        # Возьмем все последовательности токенов, соответствующие данному примеру.\n",
        "        for feature_index in feature_indices:\n",
        "            # Предсказание модели вероятности логитов.\n",
        "            start_logits = all_start_logits[feature_index]\n",
        "            end_logits = all_end_logits[feature_index]\n",
        "            # offset_mapping для восстановления ответа в изначальном контексте\n",
        "            offset_mapping = features[\"offset_mapping\"][feature_index]\n",
        "\n",
        "            # Рассмотрим все варианты ответов для первых n_best_size возможных комбинаций начального и конечного логита \n",
        "            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "            for start_index in start_indexes:\n",
        "                for end_index in end_indexes:\n",
        "                    # Выкинем невозможные ответы - это те ответы, у которых индексы токенов вылетели за границы или\n",
        "                    # индексы не попали в область контекста\n",
        "                    if (\n",
        "                        start_index >= len(offset_mapping)\n",
        "                        or end_index >= len(offset_mapping)\n",
        "                        or offset_mapping[start_index] is None\n",
        "                        or offset_mapping[end_index] is None\n",
        "                        or len(offset_mapping[start_index])==0\n",
        "                        or len(offset_mapping[end_index])==0\n",
        "                    ):\n",
        "                        continue\n",
        "                    # Не рассматриваем ответы с длиной < 0, либо > max_answer_length.\n",
        "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "                        continue\n",
        "\n",
        "                    start_char = offset_mapping[start_index][0]\n",
        "                    end_char = offset_mapping[end_index][1]\n",
        "                    valid_answers.append(\n",
        "                        {\n",
        "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                            \"text\": example[start_char: end_char]\n",
        "                        }\n",
        "                    )\n",
        "        \n",
        "      # Выбираем лучший ответ\n",
        "    if len(valid_answers) > 0:\n",
        "      best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "    else:\n",
        "      # Если у нас нет ненулевых ответов, то выдаем нулевой ответ\n",
        "      best_answer = {\"text\": \"Не получилось найти ответ, пожалуйста, переформулируйте вопрос\", \"score\": 0.0}\n",
        "\n",
        "    return best_answer"
      ],
      "metadata": {
        "id": "TQShb8QpZzLU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "174d7b6c-fd0d-4948-e95f-7de01fd66770"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Протестируем работу системы на нескольких вопросах"
      ],
      "metadata": {
        "id": "stk07ZBzsQUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'Последний император России?'\n",
        "get_answer_to_question(question, model, n_search_pages=2, max_answer_length=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "r0z6aCmpURdW",
        "outputId": "3e23ed47-a14b-47a8-d2e0-7f667c3b1eab"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "По запросу найдены следующие страницы\n",
            "<WikipediaPage 'Николай II'>\n",
            "<WikipediaPage 'Последний император'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 10.712574, 'text': 'Николая II'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'Когда родился Пушкин?'\n",
        "get_answer_to_question(question, model, n_search_pages=1, max_answer_length=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "VKkP1Yy8m0AA",
        "outputId": "a919eb66-c4ef-4c73-e60c-bb218b4c5c4b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "По запросу найдены следующие страницы\n",
            "<WikipediaPage 'Пушкин, Александр Сергеевич'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 11.1438055, 'text': '26 мая (6 июня) 1799 г.'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'От чего умер Пушкин?'\n",
        "get_answer_to_question(question, model, n_search_pages=1, max_answer_length=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "esBYX7gDoC6d",
        "outputId": "5687af19-d92a-47d8-acbb-df0c060e6462"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "По запросу найдены следующие страницы\n",
            "<WikipediaPage 'Последняя дуэль и смерть Александра Пушкина'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 12.046791, 'text': 'от перитонита'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'Какие страны входили в Антанту?'\n",
        "get_answer_to_question(question, model, n_search_pages=2, max_answer_length=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "v1cx_sMNqa9V",
        "outputId": "d2f5d126-e24a-4b35-8dbb-7fbfc57b5656"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "По запросу найдены следующие страницы\n",
            "<WikipediaPage 'Иностранная военная интервенция в России'>\n",
            "<WikipediaPage 'Первая мировая война'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 13.81327,\n",
              " 'text': 'Российская империя, Британская империя, Французская республика и союзники'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'Что такое инфляция?'\n",
        "get_answer_to_question(question, model, n_search_pages=2, max_answer_length=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "IKA0ixCjr2RN",
        "outputId": "5a994796-cc44-4c3a-ae34-a2511f4395fd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "По запросу найдены следующие страницы\n",
            "<WikipediaPage 'Инфляция'>\n",
            "<WikipediaPage 'Галопирующая инфляция'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 8.918312, 'text': 'повышение общего уровня цен на товары и услуги'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PW3gieessLRV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}